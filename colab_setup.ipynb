{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDM Quadratic Dataset Setup for Google Colab\n",
    "\n",
    "This notebook helps you set up and run the Hilbert Diffusion Model for Quadratic dataset on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone or Upload the Code\n",
    "\n",
    "First, upload your HDM-1 folder to Colab or clone from a repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have the code in a GitHub repository, uncomment and modify:\n",
    "# !git clone https://github.com/your-username/HDM-1.git\n",
    "# %cd HDM-1\n",
    "\n",
    "# Or if you uploaded a zip file:\n",
    "# !unzip HDM-1.zip\n",
    "# %cd HDM-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops matplotlib numpy pandas scipy tensorboard tensorly tensorly-torch tqdm transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python main.py --config hdm_quadratic_fno.yml --doc quadratic_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from trained model\n",
    "!python main.py --config hdm_quadratic_fno.yml --doc quadratic_experiment --sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Find the latest generated samples\n",
    "sample_files = glob.glob('exp/samples/images/*.npy')\n",
    "if sample_files:\n",
    "    latest_file = max(sample_files, key=lambda x: os.path.getctime(x))\n",
    "    samples = np.load(latest_file)\n",
    "    \n",
    "    # Plot first 6 samples\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    x = np.linspace(-10, 10, samples.shape[1])\n",
    "    \n",
    "    for i in range(min(6, len(samples))):\n",
    "        axes[i].plot(x, samples[i])\n",
    "        axes[i].set_title(f'Sample {i+1}')\n",
    "        axes[i].set_xlabel('x')\n",
    "        axes[i].set_ylabel('y')\n",
    "        axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No samples found. Make sure to run sampling first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir exp/tensorboard/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}